<!DOCTYPE html>
<!-- Gabriel Avila, Guilherme Prandi, João Victor Nery, Victor Camargo-->
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Compilador, entre aspas</title>
    <style>
      @import url('styles.css');
    </style>
    <script src="https://cdn.jsdelivr.net/npm/brython@3.10.6/brython.min.js"></script>
    <link href="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/prettify.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/prettify.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/MarketingPipeline/Markdown-Tag/markdown-tag.js"></script>
</head>
<body onload="brython(); prettyPrint()">
    <div class="sidebar">
        <h2>Index</h2>
        <a href="#readme">README</a>
        <a href="#test-cases">Test Cases</a>
        <a href="#input">Input</a>
        <a href="#lexical-analysis">Lexical Analysis</a>
        <a href="#derivation-table">Derivation Table</a>
        <a href="#parse-tree">Parse Tree</a>
        <a href="#lexical-analysis-code">Lexical Analysis Code</a>
        <a href="#syntactical-analysis-code">Syntactical Analysis Code</a>
    </div>
    <div class="content-wrapper">
        <main>
            <section id="readme">
                <h2>README</h2>
                <div id="readmeContent">
                    <md>
# INE5622 - Introdução a Compiladores

Esse projeto visa construir um analisador léxico e um analisador sintático, para os quais serão utilizados em cima de uma gramática LL(1), identificando códigos válidos ou erros léxicos e sintáticos em cima do código fornecido.

Feito por: Gabriel Ávila, Guilherme Prandi, João Victor Nery e Victor Camargo

## Funcionalidades

- Analisador Léxico
- Analisador Sintático
- Visualização da Parse tree

## Instruções para execução

1. Digite ou cole seu código LSI-2024-1 na área de texto de entrada.
2. Clique no botão "Analisar" para realizar a análise léxica e sintática.
3. Veja os resultados da análise léxica na tabela.
4. Veja os passos de derivação e a árvore de análise.

## Casos de teste
- Programa válido
- Programa com erros léxicos
- Programa com erros sintáticos

                    </md>
                </div>
            </section>
            <hr>

            <section id="test-cases">
                <h2>Test Cases</h2>
                <div>
                    <h3>Valid Program</h3>
                    <pre id="validProgram"></pre>
                    <button id="testValidProgramButton">Test Valid Program</button>
                </div>
                <div>
                    <h3>Lexical Errors</h3>
                    <pre id="lexicalError1"></pre>
                    <button id="testLexicalError1Button">Test Lexical Error 1</button>
                    <pre id="lexicalError2"></pre>
                    <button id="testLexicalError2Button">Test Lexical Error 2</button>
                    <pre id="lexicalError3"></pre>
                    <button id="testLexicalError3Button">Test Lexical Error 3</button>
                </div>
                <div>
                    <h3>Syntactical Errors</h3>
                    <pre id="syntaxError1"></pre>
                    <button id="testSyntaxError1Button">Test Syntax Error 1</button>
                    <pre id="syntaxError2"></pre>
                    <button id="testSyntaxError2Button">Test Syntax Error 2</button>
                    <pre id="syntaxError3"></pre>
                    <button id="testSyntaxError3Button">Test Syntax Error 3</button>
                </div>
            </section>
            <hr>
            
            <section id="input">
                <h2>Input</h2>
                <textarea id="inputParagraph" placeholder="Type your input here!"></textarea>
                <button id="analyzeButton">Analyze</button>
                <div id="output"></div>
            </section>
            <hr>
            
            <section id="lexical-analysis">
                <h2>Lexical Analysis</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Position</th>
                            <th>Token</th>
                        </tr>
                    </thead>
                    <tbody id="tokenTableBody">
                    </tbody>
                </table>
            </section>
            <hr>

            <section id="derivation-table">
                <h2>Derivation Table</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Step</th>
                            <th>Stack</th>
                            <th>Derivation</th>
                            <th>Current String</th>
                        </tr>
                    </thead>
                    <tbody id="derivationTableBody">
                    </tbody>
                </table>
            </section>
            <hr>

            <section id="parse-tree">
                <h2>Parse Tree</h2>
                <div class="zoom-controls">
                    <button id="zoomInButton">Zoom In</button>
                    <button id="zoomOutButton">Zoom Out</button>
                </div>
                <div class="tree">
                    <ul id="tree"></ul>
                </div>
            </section>
            <hr>

            <section id="lexical-analysis-code">
                <h2>Lexical Analysis Code</h2>
                <pre class="prettyprint lang-py">
                    <code>
    class Lexer:
        def __init__(self, source_code):
            self.source_code = source_code #Input código
            self.position = 0 #Guarda o index do input para saber em qual caracter está o AL
            self.line = 1 #Identifica linha do input
            self.column = 0 #Identifica coluna do input
            self.current_char = self.source_code[self.position] #Char atual percorrido
            self.error_msg = 0
            self.reserved_words = { #Palavras reservadas
            'def': 'DEF',
            'int': 'INT',
            'return': 'RETURN',
            'if': 'IF',
            'else': 'ELSE',
            'print': 'PRINT',
            'call': 'CALL'
            }
            self.special_chars = { #Caracteres especiais
            '+': 'PLUS',
            '-': 'MINUS',
            '*': 'MULT',
            '(': 'LPAREN',
            ')': 'RPAREN',
            '{': 'LBRACK',
            '}': 'RBRACK',
            ',': 'COMMA',
            ';': 'SEMIC',
            '>': 'GT',
            '<': 'LT',
            '=': 'ASSIGN',
            '==': 'EQ'
            }

    #Percorre caracter por caracter e atualiza atributos de linha, coluna e caracter conforme necessário
    def check_next_char(self):
        if self.current_char == '\n':
            self.line += 1
            self.column = 0
        else:
            self.column += 1
        self.position += 1
        if self.position < len(self.source_code):
            self.current_char = self.source_code[self.position]
        else:
            self.current_char = None

    #Identificar tokens com base nos lexemas
    def recognize_token(self):
        tokens_value = []
        token_steps = []
        while self.current_char is not None:
            if self.current_char.isspace():
                self.check_next_char()
            elif self.current_char.isalpha():
                identifier = self.identifier()
                tokens_value.append(identifier)
                token_steps.append({'position': self.position - len(identifier), 'token': identifier[0]})
            elif self.current_char.isdigit():
                number = self.number()
                tokens_value.append(number)
                token_steps.append({'position': self.position - len(number), 'token': 'num'})
            elif self.current_char == '=':
                lexeme = self.equals()
                tokens_value.append(lexeme)
                token_steps.append({'position': self.position - len(lexeme), 'token': lexeme[1]})
            elif self.current_char in self.special_chars.keys():
                if self.current_char != '(':
                    before = self.source_code[self.position - 1]
                    if before in ('=', '>', '<', '+', '-', '*'): #Para evitar criação de operadores inexistentes
                        self.error()
                tokens_value.append((self.special_chars[self.current_char], self.current_char))
                token_steps.append({'position': self.position - len(self.current_char), 'token': self.current_char})
                self.check_next_char()
            else:
                return f'Lexical error: Invalid character \'{self.current_char}\' at line {self.line - 1}, column {self.column}'
        if self.error_msg != 0:
            return self.error_msg
        tokens = self.return_tokens(tokens_value)
        token_steps.append({'position': self.position, 'token': '$'})
        display_token_table(token_steps)
        return tokens

    #Método para classificar lexema como token de tipo identificador
    def identifier(self):
        result = ''
        before = self.source_code[self.position - 1]
        if before.isdigit(): #Para evitar declaração de varíavel começando com número
            self.error()
        while self.current_char is not None and self.current_char.isalnum():
            result += self.current_char
            self.check_next_char()
        if result in self.reserved_words:
            return (self.reserved_words[result], result)
        else:
            return ('ID', result)

    #Método para classificar lexema como token de tipo num
    def number(self):
        result = ''
        while self.current_char is not None and self.current_char.isdigit():
            result += self.current_char
            self.check_next_char()
        return ('NUM', result)

    #Método para classificar lexema como token de tipo EQUAL ou ASSIGN
    def equals(self):
        before = self.source_code[self.position - 1]
        if before in ('>', '<', '(', '{', '}', ',', ';', '+', '-', '*'): #Evitar criação de operadores inexistentes
            self.error()
        self.check_next_char()
        if self.current_char == '=' :
            self.check_next_char()
            return ('EQ', '==')
        else:
            return ('ASSIGN', '=')

    #Método para retornar lista de tokens identificados do input no formato desejado
    def return_tokens(self, tokens_value):
        final = []
        values = self.special_chars.values()
        for token in tokens_value:
            if token[0] in values:
                final.append(token[1])
            else:
                final.append(token[0].lower())
        final.append('$')
        return final

    #Método para lançar exceção caso erro léxico seja identificado
    def error(self):
        self.error_msg = f'Lexical error: Invalid character \'{self.current_char}\' at line {self.line}, column {self.column}'

# ToDo ver se reconhece os tokens que precisa
def lexical_analyzer(input):
    lexer = Lexer(input)
    try:
        tokens = lexer.recognize_token()
        return tokens
    except Exception as e:
        pass
                    </code>
                </pre>
            </section>

            <section id="syntactical-analysis-code">
                <h2>Syntactical Analysis Code</h2>
                <pre class="prettyprint lang-py">
                    <code>
def parse(tokens):
    stack = ['$', 'MAIN']
    index = 0

    while len(stack) > 1 or index < len(tokens) - 1:
        token = tokens[index]
        top = stack.pop()
        if token == 'ELSE_DANGLING':
            pass
        elif top == token:
            index += 1
        elif top in parsing_table and token in parsing_table[top]:
            production = parsing_table[top][token]
            stack.extend(reversed([x for x in production if x != 'ε']))
        else:
            return {'result': f"Syntax error: expected '{top}' but found '{token}' at position {index}", 'derivation_steps': derivation_steps, 'parse_tree': parse_tree}
    return 'ta jóia!'

    parsing_table = {
        'ATRIBST': {'id': ['id', '=', "ATRIBST'"]},
        "ATRIBST'": {'(': ['EXPR'],
                'call': ['FCALL'],
                'id': ['EXPR'],
                'num': ['EXPR']},
        'COMP_EXPR': {')': ['ε'],
                ';': ['ε'],
                '<': ['<', 'NUMEXPR'],
                '==': ['==', 'NUMEXPR'],
                '>': ['>', 'NUMEXPR']},
        'EXPR': {'(': ['NUMEXPR', 'COMP_EXPR'],
                'id': ['NUMEXPR', 'COMP_EXPR'],
                'num': ['NUMEXPR', 'COMP_EXPR']},
        'FACTOR': {'(': ['(', 'NUMEXPR', ')'], 'id': ['id'], 'num': ['num']},     
        'FCALL': {'call': ['call', 'id', '(', 'PARLISTCALL', ')']},
        'FDEF': {'def': ['def', 'id', '(', 'PARLIST', ')', '{', 'STMTLIST', '}']},
        'FLIST': {'def': ['FDEF', "FLIST'"]},
        "FLIST'": {'$': ['ε'], 'def': ['FLIST']},
        'IFSTMT': {'if': ['if', '(', 'EXPR', ')', 'STMT', "IFSTMT'"]},
        "IFSTMT'": {'$': ['ε'],
                ';': ['ε'],
                'else': ['ELSE_DANGLING'],
                'id': ['ε'],
                'if': ['ε'],
                'int': ['ε'],
                'print': ['ε'],
                'return': ['ε'],
                '{': ['ε'],
                '}': ['ε']},
        'MAIN': {'$': ['ε'],
                ';': ['STMT'],
                'def': ['FLIST'],
                'id': ['STMT'],
                'if': ['STMT'],
                'int': ['STMT'],
                'print': ['STMT'],
                'return': ['STMT'],
                '{': ['STMT']},
        'NUMEXPR': {'(': ['TERM', "NUMEXPR'"],
                'id': ['TERM', "NUMEXPR'"],
                'num': ['TERM', "NUMEXPR'"]},
        "NUMEXPR'": {')': ['ε'],
                '+': ['+', 'TERM', "NUMEXPR'"],
                '-': ['-', 'TERM', "NUMEXPR'"],
                ';': ['ε'],
                '<': ['ε'],
                '==': ['ε'],
                '>': ['ε']},
        'PARLIST': {')': ['ε'], 'int': ['int', 'id', "PARLIST'"]},
        "PARLIST'": {')': ['ε'], ',': [',', 'PARLIST']},
        'PARLISTCALL': {'id': ['id', "PARLISTCALL'"]},
        "PARLISTCALL'": {')': ['ε'], ',': [',', 'PARLISTCALL']},
        'PRINTST': {'print': ['print', 'EXPR']},
        'RETURNST': {'return': ['return']},
        'STMT': {';': [';'],
                'id': ['print', ' ;'],
                'if': ['IFSTMT'],
                'int': ['int', 'id', ';'],
                'print': ['PRINTST', ';'],
                'return': ['RETURNST', ';'],
                '{': ['{', 'STMTLIST', '}']},
        'STMTLIST': {';': ['STMT', "STMTLIST'"],
                'id': ['STMT', "STMTLIST'"],
                'if': ['STMT', "STMTLIST'"],
                'int': ['STMT', "STMTLIST'"],
                'print': ['STMT', "STMTLIST'"],
                'return': ['STMT', "STMTLIST'"],
                '{': ['STMT', "STMTLIST'"]},
        "STMTLIST'": {';': ['STMTLIST'],
                'id': ['STMTLIST'],
                'if': ['STMTLIST'],
                'int': ['STMTLIST'],
                'print': ['STMTLIST'],
                'return': ['STMTLIST'],
                '{': ['STMTLIST'],
                '}': ['ε']},
        'TERM': {'(': ['TERM', "NUMEXPR'"],
                'id': ['TERM', "NUMEXPR'"],
                'num': ['TERM', "NUMEXPR'"]},
        "TERM'": {')': ['ε'],
                '*': ['*', 'FACTOR', "TERM'"],
                '+': ['ε'],
                '-': ['ε'],
                ';': ['ε'],
                '<': ['ε'],
                '==': ['ε'],
                '>': ['ε']}
}
                    </code>
                </pre>
            </section>
            <hr>
        </main>
    </div>

    <script type="text/python">
        from browser import document, alert, window

        parsing_table = {
                'ATRIBST': {'id': ['id', '=', "ATRIBST'"]},
                "ATRIBST'": {'(': ['EXPR'],
                        'call': ['FCALL'],
                        'id': ['EXPR'],
                        'num': ['EXPR']},
                'COMP_EXPR': {')': ['ε'],
                        ';': ['ε'],
                        '<': ['<', 'NUMEXPR'],
                        '==': ['==', 'NUMEXPR'],
                        '>': ['>', 'NUMEXPR']},
                'EXPR': {'(': ['NUMEXPR', 'COMP_EXPR'],
                        'id': ['NUMEXPR', 'COMP_EXPR'],
                        'num': ['NUMEXPR', 'COMP_EXPR']},
                'FACTOR': {'(': ['(', 'NUMEXPR', ')'], 'id': ['id'], 'num': ['num']},     
                'FCALL': {'call': ['call', 'id', '(', 'PARLISTCALL', ')']},
                'FDEF': {'def': ['def', 'id', '(', 'PARLIST', ')', '{', 'STMTLIST', '}']},
                'FLIST': {'def': ['FDEF', "FLIST'"]},
                "FLIST'": {'$': ['ε'], 'def': ['FLIST']},
                'IFSTMT': {'if': ['if', '(', 'EXPR', ')', 'STMT', "IFSTMT'"]},
                "IFSTMT'": {'$': ['ε'],
                        ';': ['ε'],
                        'else': ['ELSE_DANGLING'],
                        'id': ['ε'],
                        'if': ['ε'],
                        'int': ['ε'],
                        'print': ['ε'],
                        'return': ['ε'],
                        '{': ['ε'],
                        '}': ['ε']},
                'MAIN': {'$': ['ε'],
                        ';': ['STMT'],
                        'def': ['FLIST'],
                        'id': ['STMT'],
                        'if': ['STMT'],
                        'int': ['STMT'],
                        'print': ['STMT'],
                        'return': ['STMT'],
                        '{': ['STMT']},
                'NUMEXPR': {'(': ['TERM', "NUMEXPR'"],
                        'id': ['TERM', "NUMEXPR'"],
                        'num': ['TERM', "NUMEXPR'"]},
                "NUMEXPR'": {')': ['ε'],
                        '+': ['+', 'TERM', "NUMEXPR'"],
                        '-': ['-', 'TERM', "NUMEXPR'"],
                        ';': ['ε'],
                        '<': ['ε'],
                        '==': ['ε'],
                        '>': ['ε']},
                'PARLIST': {')': ['ε'], 'int': ['int', 'id', "PARLIST'"]},
                "PARLIST'": {')': ['ε'], ',': [',', 'PARLIST']},
                'PARLISTCALL': {'id': ['id', "PARLISTCALL'"]},
                "PARLISTCALL'": {')': ['ε'], ',': [',', 'PARLISTCALL']},
                'PRINTST': {'print': ['print', 'EXPR']},
                'RETURNST': {'return': ['return']},
                'STMT': {';': [';'],
                        'id': ['print', ' ;'],
                        'if': ['IFSTMT'],
                        'int': ['int', 'id', ';'],
                        'print': ['PRINTST', ';'],
                        'return': ['RETURNST', ';'],
                        '{': ['{', 'STMTLIST', '}']},
                'STMTLIST': {';': ['STMT', "STMTLIST'"],
                        'id': ['STMT', "STMTLIST'"],
                        'if': ['STMT', "STMTLIST'"],
                        'int': ['STMT', "STMTLIST'"],
                        'print': ['STMT', "STMTLIST'"],
                        'return': ['STMT', "STMTLIST'"],
                        '{': ['STMT', "STMTLIST'"]},
                "STMTLIST'": {';': ['STMTLIST'],
                        'id': ['STMTLIST'],
                        'if': ['STMTLIST'],
                        'int': ['STMTLIST'],
                        'print': ['STMTLIST'],
                        'return': ['STMTLIST'],
                        '{': ['STMTLIST'],
                        '}': ['ε']},
                'TERM': {'(': ['TERM', "NUMEXPR'"],
                        'id': ['TERM', "NUMEXPR'"],
                        'num': ['TERM', "NUMEXPR'"]},
                "TERM'": {')': ['ε'],
                        '*': ['*', 'FACTOR', "TERM'"],
                        '+': ['ε'],
                        '-': ['ε'],
                        ';': ['ε'],
                        '<': ['ε'],
                        '==': ['ε'],
                        '>': ['ε']}
        }

        class Lexer:
            def __init__(self, source_code):
                self.source_code = source_code #Input código
                self.position = 0 #Guarda o index do input para saber em qual caracter está o AL
                self.line = 1 #Identifica linha do input
                self.column = 0 #Identifica coluna do input
                self.current_char = self.source_code[self.position] #Char atual percorrido
                self.error_msg = 0
                self.reserved_words = { #Palavras reservadas
                'def': 'DEF',
                'int': 'INT',
                'return': 'RETURN',
                'if': 'IF',
                'else': 'ELSE',
                'print': 'PRINT',
                'call': 'CALL'
                }
                self.special_chars = { #Caracteres especiais
                '+': 'PLUS',
                '-': 'MINUS',
                '*': 'MULT',
                '(': 'LPAREN',
                ')': 'RPAREN',
                '{': 'LBRACK',
                '}': 'RBRACK',
                ',': 'COMMA',
                ';': 'SEMIC',
                '>': 'GT',
                '<': 'LT',
                '=': 'ASSIGN',
                '==': 'EQ'
                }

            #Percorre caracter por caracter e atualiza atributos de linha, coluna e caracter conforme necessário
            def check_next_char(self):
                if self.current_char == '\n':
                    self.line += 1
                    self.column = 0
                else:
                    self.column += 1
                self.position += 1
                if self.position < len(self.source_code):
                    self.current_char = self.source_code[self.position]
                else:
                    self.current_char = None

            #Identificar tokens com base nos lexemas
            def recognize_token(self):
                tokens_value = []
                token_steps = []
                while self.current_char is not None:
                    if self.current_char.isspace():
                        self.check_next_char()
                    elif self.current_char.isalpha():
                        identifier = self.identifier()
                        tokens_value.append(identifier)
                        token_steps.append({'position': self.position - len(identifier), 'token': identifier[0]})
                    elif self.current_char.isdigit():
                        number = self.number()
                        tokens_value.append(number)
                        token_steps.append({'position': self.position - len(number), 'token': 'num'})
                    elif self.current_char == '=':
                        lexeme = self.equals()
                        tokens_value.append(lexeme)
                        token_steps.append({'position': self.position - len(lexeme), 'token': lexeme[1]})
                    elif self.current_char in self.special_chars.keys():
                        if self.current_char != '(':
                            before = self.source_code[self.position - 1]
                            if before in ('=', '>', '<', '+', '-', '*'): #Para evitar criação de operadores inexistentes
                                self.error()
                        tokens_value.append((self.special_chars[self.current_char], self.current_char))
                        token_steps.append({'position': self.position - len(self.current_char), 'token': self.current_char})
                        self.check_next_char()
                    else:
                        return f'Lexical error: Invalid character \'{self.current_char}\' at line {self.line}, column {self.column}'
                if self.error_msg != 0:
                    return self.error_msg
                tokens = self.return_tokens(tokens_value)
                token_steps.append({'position': self.position, 'token': '$'})
                display_token_table(token_steps)
                return tokens

            #Método para classificar lexema como token de tipo identificador
            def identifier(self):
                result = ''
                before = self.source_code[self.position - 1]
                if before.isdigit(): #Para evitar declaração de varíavel começando com número
                    self.error()
                while self.current_char is not None and self.current_char.isalnum():
                    result += self.current_char
                    self.check_next_char()
                if result in self.reserved_words:
                    return (self.reserved_words[result], result)
                else:
                    return ('ID', result)

            #Método para classificar lexema como token de tipo num
            def number(self):
                result = ''
                while self.current_char is not None and self.current_char.isdigit():
                    result += self.current_char
                    self.check_next_char()
                return ('NUM', result)

            #Método para classificar lexema como token de tipo EQUAL ou ASSIGN
            def equals(self):
                before = self.source_code[self.position - 1]
                if before in ('>', '<', '(', '{', '}', ',', ';', '+', '-', '*'): #Evitar criação de operadores inexistentes
                    self.error()
                self.check_next_char()
                if self.current_char == '=' :
                    self.check_next_char()
                    return ('EQ', '==')
                else:
                    return ('ASSIGN', '=')

            #Método para retornar lista de tokens identificados do input no formato desejado
            def return_tokens(self, tokens_value):
                final = []
                values = self.special_chars.values()
                for token in tokens_value:
                    if token[0] in values:
                        final.append(token[1])
                    else:
                        final.append(token[0].lower())
                final.append('$')
                return final

            #Método para lançar exceção caso erro léxico seja identificado
            def error(self):
                self.error_msg = f'Lexical error: Invalid character \'{self.current_char}\' at line {self.line - 1}, column {self.column}'

        # ToDo ver se reconhece os tokens que precisa
        def lexical_analyzer(input):
            lexer = Lexer(input)
            try:
                tokens = lexer.recognize_token()
                return tokens
            except Exception as e:
                pass

        def parse(tokens):
            # Inicialização da pilha com símbolo final e inicial
            stack = ['$', 'MAIN']

            index = 0
            step_number = 0

            #Inicialização da árvore de derivação 
            derivation_steps = [{'step': step_number, 'production': 'Start', 'current_string': 'MAIN', 'stack': ' '.join(reversed(stack))}]

            parse_tree = {'value': 'MAIN', 'children': []}
            parse_stack = [{'node': parse_tree, 'token': 'MAIN'}]
            count_linhas = 0  # para ajudar a debugar no console

            # Enquanto a pilha conter mais de um elemento e o indice estar dentro do limite do vetor de tokens
            while len(stack) > 1 or index < len(tokens) - 1:

                # Obtenção do token atual
                token = tokens[index]
                print(f"{count_linhas} Stack: {stack}, Token: {token}")
                count_linhas += 1
                
                # Atualizando o ultimo elemento da pilha
                top = stack.pop()

                #print(f"Stack: {stack}, Token: {token}")
                current_parse_node = parse_stack.pop()

                if top == token:
                    index += 1
                elif top in parsing_table and token in parsing_table[top]:
                    production = parsing_table[top][token]
                    if production == 'ELSE_DANGLING':
                        production = ['']  # prandi... tem que fazer a production virar ['ε'] ou ['else', 'STMT'], como decidir isso é o desafio. Recomendo experimentar monstando programas com a linguagem que usem if. Checa o arquivo gramatica/4_fatorado.txt para entender a linguagem
                    stack.extend(reversed([x for x in production if x != 'ε']))

                    # Para desenhar á arvore de derivação
                    derivation_steps.append({'step': step_number, 'production': f"{top} → {' '.join(production)}", 'current_string': ''.join(stack), 'stack': ' '.join(reversed(stack))})
                    
                    #Atualização da árvore de análise sintática
                    for symbol in reversed(production):
                        if symbol != 'ε':
                            new_node = {'value': symbol, 'children': []}
                            current_parse_node['node']['children'].append(new_node)
                            parse_stack.append({'node': new_node, 'token': symbol})
                else:
                    # Tratamento de erros
                    return {'result': f"Syntax error: expected '{top}' but found '{token}' at position {index}", 'derivation_steps': derivation_steps, 'parse_tree': parse_tree}
                step_number += 1

            # Para desenhar á arvore de derivação
            derivation_steps.append({'step': step_number + 1, 'production': 'End', 'current_string': ''.join(stack), 'stack': ' '.join(reversed(stack))})

            return {'result': "Accepted", 'derivation_steps': derivation_steps, 'parse_tree': parse_tree}

        def display_token_table(token_steps):
            table_body = document['tokenTableBody']
            table_body.clear()
            for step in token_steps:
                row = document.createElement('tr')
                position_cell = document.createElement('td')
                position_cell.text = str(step['position'])
                token_cell = document.createElement('td')
                token_cell.text = step['token']
                row <= position_cell
                row <= token_cell
                table_body <= row

        def display_derivation_table(derivation_steps):
            table_body = document['derivationTableBody']
            table_body.clear()
            for step in derivation_steps:
                row = document.createElement('tr')
                step_number_cell = document.createElement('td')
                step_number_cell.text = str(step['step'])
                stack_cell = document.createElement('td')
                stack_cell.text = step['stack']
                step_cell = document.createElement('td')
                step_cell.text = step['production']
                current_string_cell = document.createElement('td')
                current_string_cell.text = step['current_string']
                row <= step_number_cell
                row <= stack_cell
                row <= step_cell
                row <= current_string_cell
                table_body <= row

        def generate_tree_html(node):
            if not node:
                return ''

            css_class = 'non-terminal' if node['children'] else 'terminal'

            html = f'<li><a href="#" class="{css_class}">{node["value"]}</a>'
            if node['children']:
                html += '<ul>'
                for child in node['children']:
                    html += generate_tree_html(child)
                html += '</ul>'
            html += '</li>'
            return html

        def analyze_input(event):
            document['output'].clear()
            input_text = document['inputParagraph'].value.strip()
            if input_text:
                tokens = lexical_analyzer(input_text)
                print(tokens)
                if isinstance(tokens, str):
                    print('passou para o erro')
                    document['output'].text = tokens
                else:
                    print('passou para o parse')
                    result = parse(tokens)
                    document['output'].text = result['result']
                    if 'derivation_steps' in result:
                        display_derivation_table(result['derivation_steps'])
                    if result['result'] == "Accepted":
                        document['tree'].innerHTML = generate_tree_html(result['parse_tree'])

        def run_test_case(event):
            case_id = event.target.getAttribute("data-case-id")
            input_text = document[case_id].text
            document['inputParagraph'].value = input_text
            analyze_input(None)

        def zoom_in(event):
            tree = document.querySelector('#parse-tree .tree')
            current_scale = get_current_scale(tree)
            new_scale = current_scale + 0.1
            tree.style.transform = f'scale({new_scale})'

        def zoom_out(event):
            tree = document.querySelector('#parse-tree .tree')
            current_scale = get_current_scale(tree)
            new_scale = max(0.1, current_scale - 0.1)
            tree.style.transform = f'scale({new_scale})'

        def get_current_scale(element):
            transform = element.style.transform
            if transform.startswith('scale('):
                return float(transform.split('(')[1].split(')')[0])
            return 1.0

        document['analyzeButton'].bind('click', analyze_input)

        # valido
        document['validProgram'].text = """
        def main() {
            int a;
            int b;
            a = 5;
            b = 10;
            if(a < b) {
                print a;
            } else {
                print b;
            }
            a = add(a, b);
            print a;
        }
        
        def add(int x, int y) {
            int sum;
            sum = x + y;
            return;
        }
        
        def factorial(int n) {
            int result;
            if(n == 1) {
                result = 1;
            } else {
                result = n * factorial(n - 1);
            }
            return;
        }
        
        def printNumber() {
            int number;
            number = 15;
            print number;
        }
        
        def max(int x, int y) {
            if(x > y) {
                return;
            } else {
                return;
            }
        }
        
        def test() {
            int num1;
            int num2;
            num1 = 8;
            num2 = 12;
            print max(num1, num2);
        }        
        """

        # sintaticos
        document['syntaxError1'].text = """
        def func1 ( int A , int B )
        def main() {
            int x;
            x = 5;
            if (x < 10) {
                print(x);
                anotherFunction(x);
            } else {
                x = x - 1;
                print(x);
            }
            return;
        }
        
        def anotherFunction(a) {  
            if (a > 5) {
                a = a * 2;
                print(a);
            } else {
                a = a + 2;
                print(a);
            }
        }
        """

        document['syntaxError2'].text = """
        def main() {
            int x;
            x = 5;
            print(x);
            if (x < 10) {
                x = x + 1;
            } else {
                x = x - 1;
            }
            anotherFunction();
            return;
        }
        
        def anotherFunction() {
            int a;
            a = 10;
            b = a * 2;  
            print(a);
        }
        """

        document['syntaxError3'].text = """
        def main() {
            int x;
            x = 5;
            if (x < 10) {
                print(x);
                anotherFunction(x);
            } else {
                x = x - 1;
                print(x);
            }
            return;
        }
        
        def anotherFunction(int a) {
            if (a > 5) {
                a = a * 2;
                print(a);
        
        }
        """

        document['testValidProgramButton'].bind('click', run_test_case)
        document['testValidProgramButton'].setAttribute("data-case-id", "validProgram")
        document['testLexicalError1Button'].bind('click', run_test_case)
        document['testLexicalError1Button'].setAttribute("data-case-id", "lexicalError1")
        document['testLexicalError2Button'].bind('click', run_test_case)
        document['testLexicalError2Button'].setAttribute("data-case-id", "lexicalError2")
        document['testLexicalError3Button'].bind('click', run_test_case)
        document['testLexicalError3Button'].setAttribute("data-case-id", "lexicalError3")
        document['testSyntaxError1Button'].bind('click', run_test_case)
        document['testSyntaxError1Button'].setAttribute("data-case-id", "syntaxError1")
        document['testSyntaxError2Button'].bind('click', run_test_case)
        document['testSyntaxError2Button'].setAttribute("data-case-id", "syntaxError2")
        document['testSyntaxError3Button'].bind('click', run_test_case)
        document['testSyntaxError3Button'].setAttribute("data-case-id", "syntaxError3")

        document['zoomInButton'].bind('click', zoom_in)
        document['zoomOutButton'].bind('click', zoom_out)
    </script>
</body>
</html>
